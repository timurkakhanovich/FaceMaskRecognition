{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from model.resnet import Resnet18Triplet\n",
    "from validation import evaluate_lfw\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.distance import PairwiseDistance\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler \n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from Datasets.LFWDataset import LFWDataset\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import interpolate\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import os\n",
    "import multiprocessing\n",
    "import glob\n",
    "import gc\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "torch.cuda.empty_cache()\n",
    "os.cpu_count()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Image Loader  \n",
    "class TripletFaceDataset(Dataset):\n",
    "    def __init__(self, root_dir, face_data, num_triplets, classes=100, batch_size=1, \n",
    "                  num_identities_per_batch=32, transform=None, num_workers=0):\n",
    "        self.data_path = os.path.join(root_dir, face_data)\n",
    "        self.data_dir = list(map(lambda cur_folder: \n",
    "                                os.path.join(self.data_path, cur_folder), \n",
    "                                sorted(os.listdir(self.data_path))))\n",
    "\n",
    "        self.num_workers = num_workers if num_workers != 0 else os.cpu_count()\n",
    "\n",
    "        self.num_triplets = num_triplets\n",
    "        self.batch_size = batch_size\n",
    "        self.num_identities_per_batch = num_identities_per_batch\n",
    "        self.transform = transform\n",
    "        self.classes = classes\n",
    "        self.triplets = self.multiprocess_generate_triplets()\n",
    "\n",
    "    def generate_triplets(self, num_triplets_per_process, process_id):\n",
    "        randomstate = np.random.RandomState(seed=None)\n",
    "        labels = np.load('Data/labels.npy')\n",
    "\n",
    "        num_iterations_per_epoch = num_triplets_per_process // self.batch_size\n",
    "\n",
    "        triplets = np.zeros((num_iterations_per_epoch, self.batch_size, 5))\n",
    "        for iter_idx, training_iteration in enumerate(range(num_iterations_per_epoch)):   \n",
    "            triplets_within_batch = []\n",
    "            classes_subset_for_triplets = randomstate.choice(self.classes, self.num_identities_per_batch)  # per batch  \n",
    "\n",
    "            for triplet in range(self.batch_size):\n",
    "                pos_class = randomstate.choice(classes_subset_for_triplets)\n",
    "\n",
    "                while True:\n",
    "                    neg_class = randomstate.choice(classes_subset_for_triplets)\n",
    "\n",
    "                    if pos_class != neg_class:\n",
    "                        break\n",
    "\n",
    "                ianc, ipos = randomstate.choice(labels[pos_class], 2, replace=False)\n",
    "                ineg = randomstate.choice(labels[neg_class])\n",
    "\n",
    "                triplets_within_batch.append([\n",
    "                    pos_class,\n",
    "                    neg_class,\n",
    "                    ianc,\n",
    "                    ipos,\n",
    "                    ineg\n",
    "                ])\n",
    "\n",
    "            triplets[iter_idx] = np.array(triplets_within_batch)\n",
    "\n",
    "        np.save('Datasets/temp/temp_training_triplets_identities_{}_batch_{}_process_{}.npy'.format(\n",
    "            self.num_identities_per_batch, self.batch_size, process_id\n",
    "            ),\n",
    "            triplets\n",
    "        )\n",
    "    \n",
    "    def multiprocess_generate_triplets(self):\n",
    "        num_triplets_per_process = self.num_triplets // self.num_workers\n",
    "\n",
    "        processes = []\n",
    "        for process_id in range(self.num_workers):\n",
    "            processes.append(multiprocessing.Process(\n",
    "                target=self.generate_triplets,\n",
    "                args=(num_triplets_per_process, process_id + 1)\n",
    "            ))\n",
    "        \n",
    "        for process in processes:\n",
    "            process.start()\n",
    "        \n",
    "        for process in processes:\n",
    "            process.join()\n",
    "        \n",
    "        process_files = glob.glob('Datasets/temp/*.npy')\n",
    "\n",
    "        total_triplets = []\n",
    "        for current_file in process_files:\n",
    "            total_triplets.append(np.load(current_file).astype(int))\n",
    "            os.remove(current_file)\n",
    "        \n",
    "        return np.vstack(total_triplets)\n",
    "    \n",
    "    def get_triplet_by_indices(self, pos_class, neg_class, ianc, ipos, ineg):\n",
    "        pos_dir = os.listdir(self.data_dir[pos_class])\n",
    "        neg_dir = os.listdir(self.data_dir[neg_class])\n",
    "\n",
    "        anc_data = pos_dir[ianc]\n",
    "        pos_data = pos_dir[ipos]\n",
    "        neg_data = neg_dir[ineg]\n",
    "\n",
    "        anc = Image.open(os.path.join(self.data_dir[pos_class], anc_data))\n",
    "        pos = Image.open(os.path.join(self.data_dir[pos_class], pos_data))\n",
    "        neg = Image.open(os.path.join(self.data_dir[neg_class], neg_data))\n",
    "\n",
    "        if self.transform:\n",
    "            anc = self.transform(anc)\n",
    "            pos = self.transform(pos)\n",
    "            neg = self.transform(neg)\n",
    "        \n",
    "        return { \n",
    "                'anc_img': anc, \n",
    "                'pos_img': pos, \n",
    "                'neg_img': neg,\n",
    "                'pos_class': pos_class,\n",
    "                'neg_class': neg_class \n",
    "            }\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch = self.triplets[index]\n",
    "\n",
    "        batch_sample = []\n",
    "        for data_info in batch:\n",
    "            batch_sample.append(self.get_triplet_by_indices(*data_info))\n",
    "\n",
    "        return batch_sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.triplets)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def validate_lfw(model, lfw_dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        l2_distance = PairwiseDistance(p=2)\n",
    "        distances, labels = [], []\n",
    "\n",
    "        progress_bar = enumerate(tqdm(lfw_dataloader))\n",
    "\n",
    "        for batch_index, (data_a, data_b, label) in progress_bar:\n",
    "            data_a = data_a.to(device)\n",
    "            data_b = data_b.to(device)\n",
    "\n",
    "            output_a, output_b = model(data_a), model(data_b)\n",
    "            distance = l2_distance.forward(output_a, output_b)\n",
    "\n",
    "            distances.append(distance.cpu().detach().numpy())\n",
    "            labels.append(label.cpu().detach().numpy())\n",
    "\n",
    "        labels = np.array([sublabel for label in labels for sublabel in label])\n",
    "        distances = np.array([subdist for distance in distances for subdist in distance])\n",
    "\n",
    "        TPR, FPR, precision, recall, accuracy, roc_auc, best_distances, TAR, FAR = \\\n",
    "            evaluate_lfw(\n",
    "                distances=distances,\n",
    "                labels=labels,\n",
    "                far_target=1e-1\n",
    "            )\n",
    "\n",
    "        aver_prec = np.mean(precision)\n",
    "        std_prec = np.std(precision)\n",
    "        aver_recall = np.mean(recall)\n",
    "        std_recall = np.std(recall)\n",
    "\n",
    "        print(\"Accuracy on LFW: {:.4f}+-{:.4f}\\nPrecision: {:.4f}+-{:.4f}\\nRecall: {:.4f}+-{:.4f}\\n\"\n",
    "            \"F1-score: {:.4f}+-{:.4f}\\nROC Area Under Curve: {:.4f}\\nBest distance threshold: {:.2f}+-{:.2f}\\n\"\n",
    "            \"TAR: {:.4f}+-{:.4f} @ FAR: {:.4f}\".format(\n",
    "                np.mean(accuracy),\n",
    "                np.std(accuracy),\n",
    "                aver_prec,\n",
    "                std_prec,\n",
    "                aver_recall,\n",
    "                std_recall,\n",
    "                2*aver_prec*aver_recall/(aver_prec + aver_recall),\n",
    "                2*std_prec*std_recall/(std_prec + std_recall),\n",
    "                roc_auc,\n",
    "                np.mean(best_distances),\n",
    "                np.std(best_distances),\n",
    "                np.mean(TAR),\n",
    "                np.std(TAR),\n",
    "                np.mean(FAR)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return best_distances"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data_preprocess = {\n",
    "    'train': \n",
    "        transforms.Compose([\n",
    "        transforms.Resize(size=224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.6068, 0.4517, 0.3800],\n",
    "            std=[0.2492, 0.2173, 0.2082]\n",
    "        )\n",
    "    ]), \n",
    "    'val':\n",
    "        transforms.Compose([\n",
    "        transforms.Resize(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.6068, 0.4517, 0.3800],\n",
    "            std=[0.2492, 0.2173, 0.2082]\n",
    "        )\n",
    "    ])\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "datasets = { \n",
    "        'val': LFWDataset('Data/val/', 'Datasets/lfw_pairs.txt', transform=data_preprocess['val']),\n",
    "        'test': LFWDataset('Data/test', 'Datasets/lfw_pairs_test.txt', transform=data_preprocess['val'])\n",
    "    }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "dataloaders = {\n",
    "        'val': DataLoader(\n",
    "                dataset=datasets['val'],\n",
    "                batch_size=32,\n",
    "                num_workers=0,\n",
    "                shuffle=False\n",
    "            ),\n",
    "        'test': DataLoader(\n",
    "                dataset=datasets['test'],\n",
    "                batch_size=32,\n",
    "                num_workers=0,\n",
    "                shuffle=False\n",
    "            )\n",
    "    }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#checkpoint = torch.load('model/model_resnet18_triplet.pt')\n",
    "checkpoint = torch.load('checkpoints/train_1/checkpoint_epoch_174.pt')\n",
    "model = Resnet18Triplet(embedding_dimension=checkpoint['embedding_dimension'])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "best_distance_threshold = checkpoint['best_distance_threshold']\n",
    "curr_model_epoch = checkpoint['epoch']\n",
    "\n",
    "try:\n",
    "    prev_losses = checkpoint['losses']\n",
    "except KeyError:\n",
    "    prev_losses = []\n",
    "\n",
    "model = model.to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "optimizer = optim.Adagrad(model.parameters(), lr=0.1, initial_accumulator_value=0.1)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_model_state_dict'])\n",
    "LR_scheduler = lr_scheduler.StepLR(optimizer, step_size=15, gamma=1)  # for test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def train(model, optimizer, scheduler=None, num_epochs=5, start_epoch=-1, margin=0.2, \n",
    "        hard_triplet=True, prev_losses=[]):\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    epoch_dataset_size = 0\n",
    "    l2_distance = PairwiseDistance(p=2)\n",
    "    tripletloss = nn.TripletMarginLoss(margin=margin, p=2)\n",
    "    epoch_losses = prev_losses[:]\n",
    "\n",
    "    for epoch in range(start_epoch + 1, start_epoch + 1 + num_epochs):\n",
    "        running_corrects = 0.0\n",
    "        running_loss = 0.0\n",
    "        epoch_dataset_size = 0\n",
    "\n",
    "        print('Epoch {}/{}'.format(epoch, start_epoch + num_epochs))\n",
    "        print('-' * 20)\n",
    "\n",
    "        datasets = { \n",
    "            'train': TripletFaceDataset('Data/', 'train', batch_size=32, num_triplets=6144, transform=data_preprocess['train']),\n",
    "            'val': LFWDataset('Data/val/', 'Datasets/lfw_pairs.txt', transform=data_preprocess['val'])\n",
    "        }\n",
    "        \n",
    "        dataloaders = {\n",
    "            'train': DataLoader(datasets['train'], shuffle=True),\n",
    "            'val': DataLoader(\n",
    "                    dataset=datasets['val'],\n",
    "                    batch_size=32,\n",
    "                    num_workers=0,\n",
    "                    shuffle=False\n",
    "                )\n",
    "        }\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for batch_idx, data in enumerate(tqdm(dataloaders['train'])):\n",
    "            anch_inputs = torch.stack([d['anc_img'] for d in data]).squeeze().cuda()\n",
    "            pos_inputs = torch.stack([d['pos_img'] for d in data]).squeeze().cuda()\n",
    "            neg_inputs = torch.stack([d['neg_img'] for d in data]).squeeze().cuda()\n",
    "            pos_labels = torch.stack([d['pos_class'] for d in data]).squeeze().cuda()\n",
    "            pos_labels = torch.stack([d['neg_class'] for d in data]).squeeze().cuda()\n",
    "\n",
    "            anch_outputs = model(anch_inputs)\n",
    "            pos_outputs = model(pos_inputs)\n",
    "            neg_outputs = model(neg_inputs)\n",
    "\n",
    "            pos_distance = l2_distance(anch_outputs, pos_outputs)\n",
    "            neg_distance = l2_distance(anch_outputs, neg_outputs)\n",
    "\n",
    "            if hard_triplet:\n",
    "                hard_triplets_correct = (neg_distance - pos_distance < margin).cpu().numpy().flatten()\n",
    "\n",
    "                triplets_indices = np.where(hard_triplets_correct == True)[0]\n",
    "\n",
    "            else:\n",
    "                first_cond = (neg_distance - pos_distance < margin).cpu().numpy().flatten()\n",
    "                second_cond = (pos_distance < neg_distance).cpu().numpy().flatten()\n",
    "\n",
    "                semihard_triplets_correct = np.logical_and(first_cond, second_cond)\n",
    "\n",
    "                triplets_indices = np.where(semihard_triplets_correct == True)[0]\n",
    "\n",
    "            anch_triplet = anch_outputs[triplets_indices]\n",
    "            pos_triplet = pos_outputs[triplets_indices]\n",
    "            neg_triplet = neg_outputs[triplets_indices]\n",
    "\n",
    "            loss = tripletloss(anch_triplet, pos_triplet, neg_triplet)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            if not np.isnan(loss.item()):    \n",
    "                running_loss += loss.item() * len(triplets_indices)\n",
    "            running_corrects += len(data) - len(triplets_indices)\n",
    "            epoch_dataset_size += len(data)\n",
    "    \n",
    "\n",
    "        #epoch_loss = running_loss / datasets['train'].num_triplets\n",
    "        epoch_loss = running_loss / len(dataloaders['train'])\n",
    "        epoch_losses.append(epoch_loss)\n",
    "\n",
    "        # подразумевается, что исходный dataloaders['train'] взят из этого datasets['train'] \n",
    "        #epoch_acc = running_corrects / datasets['train'].num_triplets\n",
    "        epoch_acc = running_corrects / epoch_dataset_size\n",
    "\n",
    "        print('Train Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                epoch_loss, epoch_acc))\n",
    "\n",
    "        model.eval()\n",
    "        best_distances = validate_lfw(model, dataloaders['val'])\n",
    "\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'embedding_dimension': checkpoint['embedding_dimension'],\n",
    "            'batch_size_training': len(dataloaders['train']),\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'model_architecture': checkpoint['model_architecture'],\n",
    "            'optimizer_model_state_dict': optimizer.state_dict(),\n",
    "            'best_distance_threshold': np.mean(best_distances),\n",
    "            'losses': epoch_losses\n",
    "        }\n",
    "        \n",
    "        del dataloaders, datasets\n",
    "        gc.collect()\n",
    "        \n",
    "        torch.save(state, 'checkpoint_epoch_{}.pt'.format(epoch))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train(model, optimizer, LR_scheduler, num_epochs=70, start_epoch=curr_model_epoch, margin=0.5, prev_losses=prev_losses)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python37464bitbaseconda4f12520a107c44ccaaacdf341cde0036",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "3f800561dde6209f0c647b1ec24b295364b37801e2a63d392a491285ef4d5a88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}